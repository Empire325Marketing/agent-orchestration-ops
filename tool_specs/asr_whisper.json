{
  "name": "faster_whisper_asr",
  "version": "0.10.0",
  "description": "Faster-Whisper ASR engine for real-time speech-to-text transcription",
  "type": "asr",
  "category": "speech",
  "provider": "openai-community",
  "license": "MIT",
  "commercial_use": true,
  "model_variants": {
    "tiny": {
      "model_id": "tiny",
      "parameters": "39M",
      "vram_requirements_mb": 1024,
      "languages": ["en"],
      "rtf_gpu": 0.05,
      "rtf_cpu": 0.8,
      "recommended_use": "edge_devices"
    },
    "base": {
      "model_id": "base", 
      "parameters": "74M",
      "vram_requirements_mb": 1536,
      "languages": ["multilingual"],
      "rtf_gpu": 0.08,
      "rtf_cpu": 1.2,
      "recommended_use": "lightweight"
    },
    "small": {
      "model_id": "small",
      "parameters": "244M", 
      "vram_requirements_mb": 2048,
      "languages": ["multilingual"],
      "rtf_gpu": 0.12,
      "rtf_cpu": 2.1,
      "recommended_use": "balanced"
    },
    "medium": {
      "model_id": "medium",
      "parameters": "769M",
      "vram_requirements_mb": 4096,
      "languages": ["multilingual"],
      "rtf_gpu": 0.14,
      "rtf_cpu": 3.8,
      "recommended_use": "standard"
    },
    "large-v2": {
      "model_id": "large-v2",
      "parameters": "1550M",
      "vram_requirements_mb": 6144,
      "languages": ["multilingual"],
      "rtf_gpu": 0.15,
      "rtf_cpu": 8.2,
      "recommended_use": "production",
      "recommended": true
    },
    "large-v3": {
      "model_id": "large-v3", 
      "parameters": "1550M",
      "vram_requirements_mb": 6144,
      "languages": ["multilingual"],
      "rtf_gpu": 0.16,
      "rtf_cpu": 8.5,
      "recommended_use": "latest_quality"
    }
  },
  "endpoints": {
    "transcribe": {
      "path": "/asr/transcribe",
      "method": "POST",
      "timeout_ms": 30000,
      "max_retries": 3,
      "rate_limit": {
        "requests_per_minute": 180,
        "burst_size": 30
      }
    },
    "transcribe_streaming": {
      "path": "/asr/stream",
      "method": "WebSocket",
      "timeout_ms": 300000,
      "max_retries": 1,
      "rate_limit": {
        "concurrent_streams": 20,
        "max_duration_minutes": 60
      }
    },
    "batch_transcribe": {
      "path": "/asr/batch",
      "method": "POST",
      "timeout_ms": 600000,
      "max_retries": 2,
      "rate_limit": {
        "requests_per_minute": 30,
        "burst_size": 5
      }
    },
    "health": {
      "path": "/asr/health",
      "method": "GET",
      "timeout_ms": 5000,
      "max_retries": 1
    }
  },
  "input_schema": {
    "transcribe": {
      "type": "object",
      "required": ["audio"],
      "properties": {
        "audio": {
          "type": "string",
          "format": "base64",
          "description": "Base64 encoded audio data"
        },
        "audio_url": {
          "type": "string",
          "format": "uri",
          "description": "Alternative to audio - URL of audio file"
        },
        "model_size": {
          "type": "string",
          "enum": ["tiny", "base", "small", "medium", "large-v2", "large-v3"],
          "default": "large-v2",
          "description": "Whisper model size to use"
        },
        "language": {
          "type": "string",
          "pattern": "^[a-z]{2}$",
          "description": "ISO 639-1 language code (auto-detect if not specified)"
        },
        "task": {
          "type": "string",
          "enum": ["transcribe", "translate"],
          "default": "transcribe",
          "description": "Task to perform"
        },
        "beam_size": {
          "type": "integer",
          "minimum": 1,
          "maximum": 10,
          "default": 5,
          "description": "Beam search size"
        },
        "best_of": {
          "type": "integer", 
          "minimum": 1,
          "maximum": 10,
          "default": 5,
          "description": "Number of candidates to consider"
        },
        "temperature": {
          "type": "number",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.0,
          "description": "Sampling temperature"
        },
        "compression_ratio_threshold": {
          "type": "number",
          "minimum": 0.0,
          "maximum": 10.0,
          "default": 2.4,
          "description": "Compression ratio threshold for hallucination detection"
        },
        "log_prob_threshold": {
          "type": "number",
          "maximum": 0.0,
          "default": -1.0,
          "description": "Log probability threshold for low confidence detection"
        },
        "no_speech_threshold": {
          "type": "number",
          "minimum": 0.0,
          "maximum": 1.0,
          "default": 0.6,
          "description": "Threshold for no speech detection"
        },
        "condition_on_previous_text": {
          "type": "boolean",
          "default": true,
          "description": "Use previous text as context"
        },
        "initial_prompt": {
          "type": "string",
          "maxLength": 500,
          "description": "Initial prompt to guide transcription"
        },
        "word_timestamps": {
          "type": "boolean",
          "default": false,
          "description": "Enable word-level timestamps"
        },
        "prepend_punctuations": {
          "type": "string",
          "default": "\"'"¿([{-",
          "description": "Punctuation to prepend"
        },
        "append_punctuations": {
          "type": "string", 
          "default": "\"'.。,，!！?？:：")]}、",
          "description": "Punctuation to append"
        },
        "vad_filter": {
          "type": "boolean",
          "default": true,
          "description": "Enable Voice Activity Detection filtering"
        },
        "vad_parameters": {
          "type": "object",
          "properties": {
            "threshold": {"type": "number", "default": 0.5},
            "min_speech_duration_ms": {"type": "integer", "default": 250},
            "max_speech_duration_s": {"type": "number", "default": 30},
            "min_silence_duration_ms": {"type": "integer", "default": 2000},
            "speech_pad_ms": {"type": "integer", "default": 400}
          }
        }
      }
    },
    "transcribe_streaming": {
      "type": "object",
      "properties": {
        "model_size": {
          "type": "string",
          "enum": ["tiny", "base", "small", "medium"],
          "default": "small",
          "description": "Model size for streaming (limited to smaller models)"
        },
        "language": {
          "type": "string",
          "pattern": "^[a-z]{2}$"
        },
        "chunk_length": {
          "type": "integer",
          "minimum": 5,
          "maximum": 30,
          "default": 30,
          "description": "Audio chunk length in seconds"
        },
        "chunk_overlap": {
          "type": "integer",
          "minimum": 0,
          "maximum": 5,
          "default": 1,
          "description": "Overlap between chunks in seconds"
        }
      }
    }
  },
  "output_schema": {
    "transcribe": {
      "type": "object",
      "required": ["success", "transcription"],
      "properties": {
        "success": {
          "type": "boolean",
          "description": "Transcription success status"
        },
        "transcription": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "description": "Complete transcribed text"
            },
            "language": {
              "type": "string",
              "description": "Detected or specified language"
            },
            "language_probability": {
              "type": "number",
              "minimum": 0,
              "maximum": 1,
              "description": "Confidence in language detection"
            },
            "duration": {
              "type": "number",
              "description": "Audio duration in seconds"
            },
            "segments": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "id": {"type": "integer"},
                  "seek": {"type": "number"},
                  "start": {"type": "number"},
                  "end": {"type": "number"},
                  "text": {"type": "string"},
                  "tokens": {"type": "array", "items": {"type": "integer"}},
                  "temperature": {"type": "number"},
                  "avg_logprob": {"type": "number"},
                  "compression_ratio": {"type": "number"},
                  "no_speech_prob": {"type": "number"},
                  "words": {
                    "type": "array",
                    "items": {
                      "type": "object",
                      "properties": {
                        "word": {"type": "string"},
                        "start": {"type": "number"},
                        "end": {"type": "number"},
                        "probability": {"type": "number"}
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "processing_info": {
          "type": "object",
          "properties": {
            "model_used": {"type": "string"},
            "processing_time_ms": {"type": "number"},
            "rtf": {"type": "number"},
            "device_used": {"type": "string", "enum": ["cpu", "cuda"]},
            "vad_segments": {"type": "integer"},
            "hallucination_detected": {"type": "boolean"}
          }
        },
        "error": {
          "type": "string",
          "description": "Error message if success=false"
        }
      }
    }
  },
  "resource_requirements": {
    "gpu": {
      "memory_mb": 6144,
      "compute_capability": "6.1+",
      "preferred": true,
      "fallback_available": true
    },
    "cpu": {
      "cores": 8,
      "memory_mb": 8192,
      "fallback_performance": "degraded"
    },
    "disk_space_mb": 3072,
    "network": {
      "bandwidth_mbps": 50,
      "concurrent_connections": 30
    }
  },
  "performance_metrics": {
    "accuracy": {
      "wer_clean": 0.03,
      "wer_other": 0.05,
      "multilingual_avg": 0.045
    },
    "latency": {
      "rtf_gpu_large": 0.15,
      "rtf_cpu_large": 8.2,
      "first_token_ms": 200,
      "streaming_chunk_ms": 1000
    },
    "throughput": {
      "minutes_per_hour_gpu": 240,
      "minutes_per_hour_cpu": 45,
      "concurrent_streams": 20
    }
  },
  "cost_estimates": {
    "per_minute_gpu": 0.002,
    "per_minute_cpu": 0.008,
    "monthly_base_cost": 180,
    "scaling_factor": 1.3,
    "streaming_cost_multiplier": 1.2
  },
  "security": {
    "pii_flags": true,
    "input_validation": true,
    "audio_format_validation": true,
    "max_duration_minutes": 120,
    "supported_formats": ["wav", "mp3", "m4a", "flac", "ogg"],
    "max_file_size_mb": 100,
    "content_policy": "strict",
    "hallucination_detection": true
  },
  "monitoring": {
    "metrics": {
      "asr_requests_total": "counter",
      "asr_processing_duration_seconds": "histogram",
      "asr_errors_total": "counter",
      "asr_rtf_ratio": "histogram",
      "asr_active_streams": "gauge",
      "asr_model_load_duration_seconds": "histogram",
      "asr_vad_segments_total": "counter",
      "asr_hallucinations_detected_total": "counter"
    },
    "health_checks": {
      "liveness": "/asr/health",
      "readiness": "/asr/ready",
      "model_health": "/asr/model/status",
      "interval_seconds": 30
    },
    "alerts": {
      "high_error_rate": ">3%",
      "high_rtf": ">1.0 for GPU",
      "high_latency": "p95 >5s",
      "gpu_memory_high": ">85%",
      "hallucination_rate": ">10%",
      "model_load_failure": "count >1"
    }
  },
  "deployment": {
    "container_image": "ghcr.io/guillaumekln/faster-whisper:latest-gpu",
    "model_loading": {
      "lazy_loading": false,
      "download_root": "/models/whisper",
      "compute_type": "float16",
      "cpu_threads": 4,
      "num_workers": 1
    },
    "scaling": {
      "min_replicas": 2,
      "max_replicas": 10,
      "target_gpu_utilization": 70,
      "scale_up_threshold": "queue_length >5",
      "scale_down_threshold": "queue_length <2"
    },
    "environment_variables": {
      "WHISPER_MODEL": "large-v2",
      "WHISPER_DEVICE": "cuda",
      "WHISPER_COMPUTE_TYPE": "float16",
      "ENABLE_VAD": "true",
      "MAX_CONCURRENT_REQUESTS": "10"
    }
  },
  "integration": {
    "whisperx_compatible": true,
    "diarization_support": true,
    "streaming_support": true,
    "batch_processing": true,
    "webhook_callbacks": true
  },
  "fallback": {
    "primary": "openai_whisper_cpu",
    "conditions": ["gpu_unavailable", "model_load_failure", "high_latency"],
    "timeout_ms": 15000,
    "fallback_model": "medium"
  }
}
