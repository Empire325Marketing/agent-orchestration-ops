
version: "3.9"
services:
  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]

  litellm:
    image: ghcr.io/berriai/litellm:latest
    env_file: ../../env/router.dev.env
    ports: ["4000:4000"]
    depends_on: [redis]

  vllm:
    image: vllm/vllm-openai:latest
    command: ["--model","meta-llama/Meta-Llama-3.1-8B-Instruct","--gpu-memory-utilization","0.90","--max-num-seqs","128","--max-model-len","32768","--enable-prefix-caching"]
    runtime: nvidia
    environment: { NVIDIA_VISIBLE_DEVICES: "all" }
    ports: ["8000:8000"]
